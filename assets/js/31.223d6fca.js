(window.webpackJsonp=window.webpackJsonp||[]).push([[31],{513:function(t,a,s){"use strict";s.r(a);var r=s(4),e=Object(r.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"chatglm的本地部署"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#chatglm的本地部署"}},[t._v("#")]),t._v(" chatGLM的本地部署")]),t._v(" "),s("p",[t._v("前段时间，清华大学开源了国产的双语对话语言模型chatGLM。和openAI的chatGPT相比还是有很多不足之处，但是它体量小，能够在消费级显卡上部署。"),s("br"),t._v("\n在这里主要介绍本地部署的过程和我遇到的问题。"),s("br"),t._v("\n首先克隆仓库到本地")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("git clone https://github.com/THUDM/ChatGLM-6B.git\n")])])]),s("p",[t._v("使用 pip 安装依赖：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("pip install -r requirements.txt\n")])])]),s("p",[t._v("然后运行命令行 Demo")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("python cli_demo.py\n")])])]),s("p",[t._v("程序会自动下载模型和剩余的依赖"),s("br"),t._v("\n假如之后想要删除，模型的安装目录在："),s("code",[t._v("C:\\Users\\[你的用户目录]\\.cache\\huggingface\\hub")]),s("br"),t._v("\n如果运行成功没有报错，你应该会看到这个界面")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://s2.loli.net/2023/04/01/XugwdxirpVmUbnR.png",alt:"运行成功"}})]),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",[t._v("但是部署过程一般来说不可能这么顺利"),s("br"),t._v("\n你会遇到各种各样的问题")])]),t._v(" "),s("h1",{attrs:{id:"在安装时可能遇到的问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#在安装时可能遇到的问题"}},[t._v("#")]),t._v(" 在安装时可能遇到的问题")]),t._v(" "),s("h2",{attrs:{id:"显存较低"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#显存较低"}},[t._v("#")]),t._v(" 显存较低")]),t._v(" "),s("p",[t._v("如果你的电脑显存较低（小于13GB），可以修改"),s("strong",[t._v("cli_demo.py")]),t._v("文件中的：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("model "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"THUDM/chatglm-6b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trust_remote_code"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("half"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("将"),s("code",[t._v("THUDM/chatglm-6b")]),t._v(" 修改为 "),s("code",[t._v("THUDM/chatglm-6b-int4")]),t._v("或者"),s("code",[t._v("THUDM/chatglm-6b-int4-qe")]),s("br"),t._v(" "),s("strong",[t._v("chatglm-6b")]),t._v(" 是完整模型，运行需要大概"),s("strong",[t._v("13GB")]),t._v(" 显存。"),s("br"),t._v(" "),s("strong",[t._v("chatglm-6b-int4")]),t._v(" 是 4-bit 量化模型，需要大概 "),s("strong",[t._v("5.2GB")]),t._v(" 的显存。"),s("br"),t._v(" "),s("strong",[t._v("chatglm-6b-int4-qe")]),t._v("是对Embedding量化后的模型，模型参数仅占用 "),s("strong",[t._v("4.3 GB")]),t._v(" 显存。")]),t._v(" "),s("div",{staticClass:"custom-block warning"},[s("p",{staticClass:"custom-block-title"},[t._v("注意")]),t._v(" "),s("p",[t._v("仅仅是运行起来就需要5.2G的显存，后续的对话依然需要占用显存。比如我的RTX3060 Laptop，6G显存在进行两次左右的对话就会吃满显存然后直接爆掉，所以实际的实际体验可能并不能尽如人意。")])]),t._v(" "),s("h2",{attrs:{id:"gcc-不是内部或外部命令-也不是可运行的程序-或批处理文件。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#gcc-不是内部或外部命令-也不是可运行的程序-或批处理文件。"}},[t._v("#")]),t._v(" 'gcc' 不是内部或外部命令，也不是可运行的程序 或批处理文件。")]),t._v(" "),s("p",[t._v("这个报错的意思是在编译时缺少 "),s("code",[t._v("gcc")]),t._v(" 编译器，从而导致了后续的错误。")]),t._v(" "),s("p",[t._v("gcc编译器可以前往"),s("a",{attrs:{href:"https://www.mingw-w64.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("官网"),s("OutboundLink")],1),t._v("下载，这个视频有详细安装的教程。")]),t._v(" "),s("iframe",{attrs:{src:"//player.bilibili.com/player.html?aid=346010066&bvid=BV1Ld4y1u7v7&cid=848709588&page=1&autoplay=0",scrolling:"no",border:"0",frameborder:"no",framespacing:"0",allowfullscreen:"true"}}),t._v(" "),s("p",[t._v("如果在python虚拟环境中无法访问gcc编译器，可以尝试输入以下命令：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v('setx PATH "%PATH%;C:\\MinGW\\bin" \n')])])]),s("p",[t._v("这里的“C:\\MinGW\\bin”是指安装gcc编译器的路径，你需要将其替换为系统上安装gcc编译器的实际路径。"),s("br"),t._v("\n这段命令的含义是设置环境变量 PATH，并将原来的 PATH 环境变量的值保留下来。"),s("br"),t._v("\n需要重新启动cmd来生效设置。")]),t._v(" "),s("h2",{attrs:{id:"assertionerror-torch-not-compiled-with-cuda-enabled"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#assertionerror-torch-not-compiled-with-cuda-enabled"}},[t._v("#")]),t._v(" AssertionError: Torch not compiled with CUDA enabled")]),t._v(" "),s("p",[t._v("这个报错提示 Torch 没有启用 CUDA 编译。如果你已经正确安装了CUDA，那可能是因为PyTorch的版本不支持")]),t._v(" "),s("p",[t._v("可以前往"),s("a",{attrs:{href:"https://pytorch.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("PyTorch官网"),s("OutboundLink")],1),t._v("下载合适的版本。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://s2.loli.net/2023/04/01/A5erDHVyTfZMdxR.png",alt:"版本选择"}})]),t._v(" "),s("p",[t._v("你可以通过在CMD中输入"),s("code",[t._v("nvcc --version")]),t._v("来查看你的CUDA版本。")]),t._v(" "),s("h3",{attrs:{id:"_2023-03-29更新"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2023-03-29更新"}},[t._v("#")]),t._v(" "),s("s",[t._v("2023/03/29更新")])]),t._v(" "),s("p",[s("s",[s("a",{attrs:{href:"https://github.com/silverriver/ChatGLM-6B-Slim",target:"_blank",rel:"noopener noreferrer"}},[t._v("silverriver"),s("OutboundLink")],1),t._v("大佬发布了裁减掉20K图片Token的模型，在不减小性能的情况下，占用更小的显存。"),s("br")]),t._v(" "),s("s",[t._v("实测能从两次对话增加到五次以上的水平。"),s("br")]),t._v(" "),s("s",[t._v("并不需要将他的仓库克隆过来，只需要将"),s("strong",[t._v("cli_demo.py")]),t._v("文件中的")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("tokenizer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoTokenizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"THUDM/chatglm-6b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trust_remote_code"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"THUDM/chatglm-6b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trust_remote_code"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("half"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("s",[t._v("替换为")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("tokenizer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoTokenizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"silver/chatglm-6b-slim"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trust_remote_code"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"silver/chatglm-6b-int4-slim"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trust_remote_code"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("half"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"_2023-04-06更新"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2023-04-06更新"}},[t._v("#")]),t._v(" 2023/04/06更新")]),t._v(" "),s("p",[t._v("官方采纳了"),s("a",{attrs:{href:"https://github.com/silverriver",target:"_blank",rel:"noopener noreferrer"}},[t._v("silverriver"),s("OutboundLink")],1),t._v("的建议，直接在官方仓库移除了embedding中的image token。")])])}),[],!1,null,null,null);a.default=e.exports}}]);